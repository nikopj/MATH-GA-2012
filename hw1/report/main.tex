\documentclass[12pt,reqno]{amsart}
\usepackage{format}
\geometry{margin=1in} % Smaller margins for more work.
\usepackage{parskip}
\usepackage{hyperref}

\usepackage{verbatim}
\usepackage{tcolorbox}
\usepackage{verbatimbox}
\usepackage{pgfplots}
\usepackage{subcaption}

\usepackage{multirow}

\lstset
{
    language=C++,
    basicstyle=\footnotesize\ttfamily,
    numbers=none,
    stepnumber=1,
    showstringspaces=false,
    tabsize=4,
    breaklines=true,
    breakatwhitespace=true,
}

\title{Homework 1}
\author{Nikola} %Janju\v{s}evi\'{c}}
\date{\today}

\makeatletter
\let\newtitle\@title
\let\newauthor\@author
\let\newdate\@date
\makeatother

\begin{document}
\noindent{\bf\normalsize MATH-GA 2012.002, Spring 2023, \newtitle} \\
{\normalsize Nikola Janju\v{s}evi\'{c}, \newdate} \\

\vspace{0.5em}

\begin{problem}[Presentation] ~ 
    On \href{https://arxiv.org/abs/2107.01739}{``KAISA: An Adaptive Second-Order Optimizer Framework for Deep
    Neural Networks"}. See
    \texttt{JANJUSEVIC\_NIKOLA.pdf} for slides.
\end{problem}

\vspace{1em}

\begin{problem}[Matrix-matrix multiplication (MMM)] ~ \\
We edit and compile \texttt{MMutl0.cpp}, a program that does 
matrix-matrix multiplication naively via a tripple nested for
loop. For multiplication matrices $C \leftarrow C + AB$ of shapes $C \in
\R^{m \times n}$, $A \in \R^{m \times k}$, and $B \in \R^{k \times n}$, 
the inner iteration at indices (i, j, p) of the loop consists of:

\begin{enumerate}[label=\arabic*), itemsep=0em]
    \item reading $A_{ip}$, $B_{pj}$, and $C_{ij}$ (i.e. 3 reads)
    \item \texttt{C\_ij += A\_ip * B\_pj} (i.e. 1 add and 1 multiply)
    \item writing to $C_{ij}$
\end{enumerate}

Hence, our total number of flops per MMM is \texttt{2mnk}, and our total memory
read/write per MMM is \texttt{4mnk * sizeof(double) = 64mnk}. Note that this is
not an optimal implementation of MMM, nor an optimal implementation of {\it naive}
MMM.

The following tests were run on an Intel Core i5-8250U CPU, a 64 bit x86
processor with a max clock frequency of 3.4 GHz and a maximum bandwidth 
of 35.76 GB/s. The processor has an L1, L2, and L3 cache size of 256 kB, 1 MB,
and 6 MB,
respectively\footnote{\href{https://en.wikichip.org/wiki/intel/core_i5/i5-8250u}{https://en.wikichip.org/wiki/intel/core\_i5/i5-8250u}}.
The code with compiled with \texttt{g++ 12.2.0}. 

\begin{figure}[hb]
  \centering
  \makebox[\linewidth][c]{%
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
          xlabel={Dimension},
          title={Time (s)},
          legend entries={O0,O3},
          legend pos=north west,
          grid=major,
          width=\textwidth,
          height=0.25\textheight,
          % cycle list name=black white,
        ]
        \addplot table[x=Dimension,y=Time,col sep=space] {../log.d/log0.txt};
        \addplot table[x=Dimension,y=Time,col sep=space] {../log.d/log3.txt};
      \end{axis}
    \end{tikzpicture}
    \caption{Runtime}
  \end{subfigure} %
  \hfill
  \begin{subfigure}{0.4\linewidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
          xlabel={Dimension},
          title={Gflop/s},
          legend entries={O0,O3},
          legend pos=north east,
          grid=major,
          width=\textwidth,
          height=0.25\textheight,
          % cycle list name=black white,
        ]
        \addplot table[x=Dimension,y=Gflop/s,col sep=space] {../log.d/log0.txt};
        \addplot table[x=Dimension,y=Gflop/s,col sep=space] {../log.d/log3.txt};
      \end{axis}
    \end{tikzpicture}
    \caption{Flops}
  \end{subfigure} %
  \hfill
  \begin{subfigure}{0.4\textwidth}
    \centering
    \begin{tikzpicture}
      \begin{axis}[
          xlabel={Dimension},
          title={GB/s},
          legend entries={O0,O3},
          legend pos=north east,
          grid=major,
          width=\textwidth,
          height=0.25\textheight,
          % cycle list name=black white,
        ]
        \addplot table[x=Dimension,y=GB/s,col sep=space] {../log.d/log0.txt};
        \addplot table[x=Dimension,y=GB/s,col sep=space] {../log.d/log3.txt};
      \end{axis}
    \end{tikzpicture}
    \caption{Bandwidth}
  \end{subfigure}
  }
  \caption{\texttt{MMult0.cpp} output over different compliation optimization
levels (O0, O3). Plotting code (\texttt{pgfplots}) generated by ChatGPT.}
  \label{fig:p2}
\end{figure}


Figure \ref{fig:p2} shows the
output of the matrix multiplication program under different optimization levels.
In this setting \texttt{M=N=K=dimension}.
We see that without optimization, the code stagnates its performance in terms of
flops and bandwidth. With optimization, the runtime increases while flops and bandwidth decrease with
optimization level dimension. The use of compiler optimization also brings the
performance of the program close to the manufacturer's specifications for the
processor. 

An interesting note is the relative plateu
of performance in the \texttt{dimension=[10,100]} range. This can be explained 
by the size of the L1 cache being 256 kB, which can hold 3 $N \times N$ matrices
of (roughly up) to size $N=103$. After dimension 100, slower forms of memory are
likely being used and we observe a sharp decrease in performance.

\end{problem}

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=0.9\textwidth]{../p1b.png}
%   \caption{HSV channels.}
%   \label{fig:p1b}
% \end{figure}

% \begin{minipage}{0.95\linewidth}
% \begin{tcolorbox}
%   \lstinputlisting[firstline=64, lastline=69,
%   numbers=none]{../ca01.py}
% \end{tcolorbox}
% \end{minipage}

\vspace{1em}

\begin{problem}[Laplace 1D] ~ \\
\texttt{laplace.cpp} (given at the end of this document) implements Jacobi and
Gauss-Seidel solvers for the 1D Laplace equation with Dirichlet boundary
conditions. The program was compared against the analytical solution $u(x) =
\frac{1}{2}x(1-x),\, x\in [0,1]$ for correctness. 
Table \ref{tab:stats} shows the statistics of the
algorithms when compiled and run on the processor described in the previous
problem.

\begin{table}[htb]
    \caption{\texttt{laplace.cpp} solver stats over dimension (N) and compiler
        optimization (O0, O3), \texttt{maxit=50000}.}
    \begin{tabular}{ccccccc}
    \multirow{2}{*}{Solver} & \multirow{2}{*}{Stats} & \multicolumn{4}{c}{Dimension (N)} \\
                         & & 10 & 100 & 1k & 100k \\\hline
    \multirow{4}{*}{Jacobi} 
                            & O0-time & \texttt{2e-4} & \texttt{0.080} & \texttt{1.85} & \texttt{156} \\
                            & O3-time & \texttt{2e-5} & \texttt{4e-3} & \texttt{0.095} & \texttt{11.4} \\
                            & iters   & 222 & 18830 & 50k & 50k \\
                            & residual & \texttt{3e-4} & \texttt{1e-2} & \texttt{22.29} & \texttt{315.4} \\\hline

    \multirow{4}{*}{Gauss-Seidel} 
                            & O0-time & \texttt{6e-4} & \texttt{0.035} & \texttt{1.79} & \texttt{145} \\
                            & O3-time & \texttt{8e-6} & \texttt{3e-3} & \texttt{0.18} & \texttt{17.9} \\
                            & iters   & 112 & 9416 & 50k & 50k \\
                            & residual & \texttt{3e-4} & \texttt{1e-2} & \texttt{22.29} & \texttt{315.4} \\\hline
    \end{tabular}
    \label{tab:stats}
\end{table}
\end{problem}

After $N=1,000$, neither solver is able to run to convergence. We observe that
the Gauss-Seidel algorithm is per-iteration slower than Jacobi but has a faster
runtime when given enough time to converge (as it uses less iterations). 
Enabling compilation optimzation speeds up both algorithms by an
order of magnitude.


\newpage
\verb!MMult0.cpp!
\lstinputlisting[numbers=left]{../MMult0.cpp}

\newpage
\verb!laplace.cpp!
\lstinputlisting[numbers=left]{../laplace.cpp}

\end{document}
